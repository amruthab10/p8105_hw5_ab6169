---
title: "p8105_hw5_ab6169"
author: "Amrutha Banda"
date: "2025-11-08"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(p8105.datasets)
library(tidyverse)
library(broom)
library(dplyr)
library(purrr)

```


# Problem 1 

```{r}
birthdays = sample(1:365, 50, replace = TRUE)

repeated_bday= length(unique(birthdays)) < 50

repeated_bday

unique(c(1,2,3,4,5,1,1,3))
```

In a function
```{r}
bday_sim= function(n_room) {
  birthdays= sample(1:365, n_room, replace = TRUE)

  repeated_bday= length(unique(birthdays)) < n_room

  repeated_bday
}

bday_sim(20)
```

```{r}
bday_sim_results= 
  expand_grid(
    bdays= 2:50, 
    iter= 1:10000
  ) |>  
  mutate(
    result= map_lgl(bdays, bday_sim)
  ) |> 
  group_by(
    bdays
  ) |>  
  summarize(
    prob_repeat= mean(result)
  )
```


Plot Showing the Probability as a function of group size 
```{r}
bday_sim_results |>
  ggplot(aes(x = bdays, y = prob_repeat)) + 
  geom_point() + 
  geom_line() +
  labs(
    x = "Group size (n)",
    y = "Probability of at least one shared birthday",
    title = "Birthday paradox via simulation (10,000 runs per n)"
  )
```
Comments: This plot shows us how probability of at least two people sharing a birthday increases as the group size grows. When there are fewer than 10 people in the room, the probability is close to zero. This means that having a shared birthday is very unlikely. Meanwhile, as the group size approaches around 20-25 people, the probability rises and reaches to about 50%. I also observed that the curve begins to flatten after about 35 people. 



# Problem 2 

```{r}
set.seed(1)
```

#Running 5000 simulations 
```{r}


```


Power of the test 
```{r}

```

Power Plot 
```{r}

```

2. Repeat the above for ðœ‡={1,2,3,4,5,6}
3. Make a plot. Describe the association between effect size and power.
4. Make another plot 


# Problem 3 

Load the Homicide Dataset
```{r}
homicide_raw= read_csv("data/homicide-data.csv", na = c("NA", ".", "")) |> 
janitor::clean_names()
```
Description of Data: 


```{r}

unsolved_levels= c("Closed without arrest", "Closed by arrest")

homicide_data= 
  homicide_raw |>
  mutate(
    city_state = paste(city, state, sep = ","),
    unsolved   = disposition %in% unsolved_levels) |>
  group_by(city_state) |>
  mutate(
    total= n(),
    unsolved_total = sum(unsolved)) |>
  ungroup() |>
  select(-city, -state, -disposition)

 
   
```

Baltimore, MD

```{r}

baltimore_df <- 
  homicide_data |> 
  filter(city_state %in% c("Baltimore, MD", "Baltimore,MD"))


baltimore_counts <- 
  baltimore_df |> 
  summarize(
    total = n(),
    unsolved = sum(unsolved, na.rm = TRUE)
  )
baltimore_counts

baltimore_test <- 
  prop.test(baltimore_counts$unsolved, baltimore_counts$total)
baltimore_test

baltimore_tidy <- 
  broom::tidy(baltimore_test) |> 
  select(estimate, conf.low, conf.high)

baltimore_tidy

```

Plot 

```{r}
city_counts <- homicide_data |>
  group_by(city_state) |>
  summarize(
    total    = n(),
    unsolved = sum(unsolved, na.rm = TRUE),
    .groups = "drop"
  )

city_results <- city_counts |>
  mutate(
    test_obj = map2(unsolved, total, ~ prop.test(.x, .y)),
    tidy_out = map(test_obj, broom::tidy)
  ) |>
  unnest(tidy_out) |>
  select(city_state, total, unsolved, estimate, conf.low, conf.high)
```

```{r fig.height=100, fig.width=100}
city_results |>
  mutate(city_state = forcats::fct_reorder(city_state, estimate)) |>
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(
    title = "Estimated proportion of unsolved homicides by city (95% CI)",
    x = NULL,
    y = "Proportion unsolved") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1))
```


